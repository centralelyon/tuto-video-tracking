{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a787399",
   "metadata": {},
   "source": [
    "# Notebook sur le tracking vidéo\n",
    "\n",
    "Dans ce notebook nous allons voir comment on peut lire une vidéo, extraire les frames de la vidéo, faire de la détection (estimation de pose) et faire du tracking sur cette détection.\n",
    "\n",
    "**Plan:**\n",
    "1. Lecture de vidéo\n",
    "2. Manipulation de frames\n",
    "3. Estimation de pose\n",
    "4. Utilisation des données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9ed7fb",
   "metadata": {},
   "source": [
    "### 0. Import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "16e3cae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import subprocess\n",
    "import json\n",
    "import pandas as pd\n",
    "import csv\n",
    "from IPython.display import Image, display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c93481",
   "metadata": {},
   "source": [
    "### 1. Lecture de vidéo\n",
    "\n",
    "Pour lire les vidéos et manipuler les images, nous allons utiliser la bibliothèque <a href='https://opencv.org/'>OpenCV<a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "edb90288",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lecture de la vidéo\n",
    "video_name = 'sample/Lebrun_Liang_table.mp4'\n",
    "\n",
    "vidcap = cv.VideoCapture(video_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09db2f33",
   "metadata": {},
   "source": [
    "### 2. Manipulation de frames\n",
    "\n",
    "Pour la manipulation de frames, nous allons reprendre la bibliothèque <a href='https://opencv.org/'>OpenCV<a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a2e74ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extraction des frames\n",
    "if not os.path.isdir('output'):\n",
    "    os.mkdir('output')\n",
    "frame_path = os.path.join('output','frames')\n",
    "\n",
    "if not os.path.isdir(frame_path):\n",
    "    os.mkdir(frame_path)\n",
    "    \n",
    "success, image = vidcap.read()\n",
    "i = 0\n",
    "while success != False:\n",
    "    #Lecture des frames\n",
    "    success, image = vidcap.read()\n",
    "    \n",
    "    #Sauvegarder les frames\n",
    "    if success:\n",
    "        cv2.imwrite(os.path.join(frame_path, str(i) + \".jpg\"), image)\n",
    "    else:\n",
    "        break\n",
    "    \n",
    "    i += 1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055e7662",
   "metadata": {},
   "source": [
    "### 3. Estimation de la pose\n",
    "\n",
    "Pour faire l'estimation de pose, nous allons utiliser <a href='https://github.com/CMU-Perceptual-Computing-Lab/openpose'>Openpose<a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "617dd461",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Répertorier les frames dans le dossier où elles ont été sauvegardées\n",
    "\n",
    "os.chdir(dossier_courant)\n",
    "liste_frame = os.listdir(frame_path)\n",
    "\n",
    "if not os.path.isdir(os.path.join('output','openpose_json')):\n",
    "    os.mkdir(os.path.join('output','openpose_json'))\n",
    "#Lancer Openpose sur les frames, Choisir où on enregistre les frames\n",
    "chemin_sauvegarde = os.path.join('output','openpose_json')\n",
    "\n",
    "path_openpose = \"C:\\\\Users\\\\ReViVD\\\\Downloads\\\\openpose-1.7.0-binaries-win64-gpu-python3.7-flir-3d_recommended\\\\openpose\"\n",
    "dossier_courant = os.getcwd()\n",
    "os.chdir(path_openpose)\n",
    "if not os.path.isdir(chemin_sauvegarde):\n",
    "    os.mkdir(chemin_sauvegarde)\n",
    "subprocess.call(\"bin\\\\OpenPoseDemo.exe --video \"+os.path.join(dossier_courant,video_name)+\" --write_json \"+os.path.join(dossier_courant,chemin_sauvegarde)+' --write_video '+os.path.join(dossier_courant,video_name.replace('.mp4','_openpose.avi'))+' --display 0')\n",
    "\n",
    "#subprocess.call(\"bin\\\\OpenPoseDemo.exe --image_dir \"+os.path.join(dossier_courant,'test')+\" --write_images \"+os.path.join(dossier_courant,'test2')+\" --write_json \"+os.path.join(dossier_courant,chemin_sauvegarde)+ ' --display 0')\n",
    "os.chdir(dossier_courant)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ce6d6c",
   "metadata": {},
   "source": [
    "### Keypoints Openpose"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d18f169",
   "metadata": {},
   "source": [
    "<img src=\"utils/openpose_keypoints.png\" width=400 height=400 />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3311adb",
   "metadata": {},
   "source": [
    "### 4. Utilisation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "8050889e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n#Ouvir le fichier csv\\nwith open(chemin_csv, newline='') as csvfile:\\n    reader = csv.reader(csvfile)\\n    next(reader) #permet de ne pas prendre l'en-tête\\n    #for row in reader:\\n        \\n\""
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Répertorier les json dans le dossier où elles ont été sauvegardées\n",
    "liste_json_openpose = os.listdir(chemin_sauvegarde)\n",
    "\n",
    "#Ouvrir les json et les récupérer les données\n",
    "liste_toutes_valeurs = []\n",
    "for le_json in liste_json_openpose:\n",
    "        if '.json' in le_json: #test pour vérifier que c'est bien un fichier json\n",
    "            data = pd.read_json(os.path.join(chemin_sauvegarde,le_json), lines=True)\n",
    "            if len(data['people'])>0: #test pour vérifier qu'il y a bien au moins une personne détectée\n",
    "                for i in range(len(data['people'][0])):\n",
    "                    data_keypoints = data['people'][0][i]['pose_keypoints_2d']\n",
    "                    for j in range(0,len(data_keypoints),3): #partie permettant de récupérer les coordonnées x, y et la confiance à chaque fois\n",
    "                        liste_un_json = []\n",
    "                        liste_un_json.append(int(le_json.split('_')[-2]))\n",
    "                        liste_un_json.append(i)\n",
    "                        liste_un_json.append(j//3)\n",
    "                        liste_un_json.append(data_keypoints[j])\n",
    "                        liste_un_json.append(data_keypoints[j+1])\n",
    "                        liste_un_json.append(data_keypoints[j+2])\n",
    "                        liste_toutes_valeurs.append(liste_un_json)\n",
    "\n",
    "#Créer un fichier csv à l'aide des json créés par Openpose\n",
    "chemin_csv_openpose = os.path.join('output','csv','openpose.csv') #chemin où on va enregistrer le csv contenant les informations openpose\n",
    "if not os.path.isdir(os.path.split(chemin_csv_openpose)[0]):\n",
    "    os.mkdir(os.path.split(chemin_csv_openpose)[0])\n",
    "    \n",
    "\n",
    "with open(chemin_csv_openpose,'w',newline='') as fichiercsv:\n",
    "    writer=csv.writer(fichiercsv)\n",
    "    writer.writerow(['frame','numero_pers','joint','x','y','confience'])\n",
    "    for l in liste_toutes_valeurs:\n",
    "        writer.writerow(l)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "c903502b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fonction permettant de tracer un rectangle à l'aide de 4 points\n",
    "def draw_rect_video(frame, posA = (10, 50), posB = (20, 70), color = (255,0,0)):\n",
    "    \"\"\"draw a rectangle given 2 points\"\"\"\n",
    "    #c = hex2rgb(colors[0])\n",
    "    #color = (c[2], c[1], c[0])\n",
    "    thickness = 6\n",
    "    cv2.rectangle(frame, posA, posB, color, thickness)\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "#Tracer des bounding box autour des joueurs à l'aide de l'estimation de pose\n",
    "def bounding_box(num_frame,chemin_image,num_personne,chemin_csv,chemin_sauvegarder,afficher_image=True):\n",
    "    if not os.path.isdir(chemin_sauvegarder):\n",
    "        os.mkdir(chemin_sauvegarder)\n",
    "    #Ouvir le fichier csv\n",
    "    with open(chemin_csv, newline='') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        next(reader) #permet de ne pas prendre l'en-tête\n",
    "        max_x,max_y,min_x,min_y = -1,-1,-1,-1\n",
    "        for row in reader:\n",
    "            if ((int(row[0]) == num_frame) and (int(row[1]) == num_personne)):\n",
    "                if max_x == -1:\n",
    "                    max_x,max_y,min_x,min_y = float(row[3]),float(row[4]),float(row[3]),float(row[4])\n",
    "                else:\n",
    "                    if ((float(row[3]) > max_x)):\n",
    "                        max_x = float(row[3])\n",
    "                    if ((float(row[4]) > max_y)):\n",
    "                        max_y = float(row[4])\n",
    "                    if (((float(row[3]) < min_x) or (min_x == 0)) and (float(row[3]) != 0)):\n",
    "                        min_x = float(row[3])\n",
    "                    if (((float(row[4]) < min_y) or (min_y == 0)) and (float(row[4]) != 0)):\n",
    "                        min_y = float(row[4])\n",
    "    \n",
    "    image = cv2.imread(chemin_image) #lire image\n",
    "    draw_rect_video(image, (int(max_x),int(max_y)), (int(min_x),int(min_y))) #tracer rectangle\n",
    "    \n",
    "    cv2.imwrite(os.path.join(chemin_sauvegarder,str(num_frame)+'.jpg'),image) #enregistrer image avec box\n",
    "    \n",
    "    if afficher_image:\n",
    "        display(Image(os.path.join(chemin_sauvegarder,str(num_frame)+'.jpg')))\n",
    "            \n",
    "#bounding_box(0,os.path.join('output','0.jpg'),0,'openpose.csv',os.path.join('output','frames_boxes'))\n",
    "#Faire des premiers calculs de métrics (vitesses, distances de déplacements,...)\n",
    "#Faire bounding box Couleur de la raquette\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "f8903c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tracer les box d'une personne sur tout un dossier\n",
    "nom_dossier = os.path.join('output','frames')\n",
    "liste_images = os.listdir(nom_dossier)\n",
    "liste_images.sort()\n",
    "liste_images.sort(key=len)\n",
    "num_personne = 0\n",
    "for i in range(len(liste_images)):\n",
    "    bounding_box(i,os.path.join(nom_dossier,liste_images[i]),num_personne,os.path.join('output','csv','openpose.csv'),os.path.join('output','frames_boxes'),afficher_image=False)\n",
    "    bounding_box(i,os.path.join(nom_dossier.replace('frames','frames_boxes'),liste_images[i]),1,os.path.join('output','csv','openpose.csv'),os.path.join('output','frames_boxes'),afficher_image=False)    \n",
    "    bounding_box(i,os.path.join(nom_dossier.replace('frames','frames_boxes'),liste_images[i]),2,os.path.join('output','csv','openpose.csv'),os.path.join('output','frames_boxes'),afficher_image=False)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
