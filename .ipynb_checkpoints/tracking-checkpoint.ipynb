{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a787399",
   "metadata": {},
   "source": [
    "# Notebook sur le tracking vidéo\n",
    "\n",
    "Dans ce notebook nous allons voir comment on peut lire une vidéo, extraire les frames de la vidéo, faire de la détection (estimation de pose) et faire du tracking sur cette détection.\n",
    "\n",
    "**Plan:**\n",
    "1. Lecture de vidéo\n",
    "2. Manipulation de frames\n",
    "3. Estimation de pose\n",
    "4. Utilisation des données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9ed7fb",
   "metadata": {},
   "source": [
    "### 0. Import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "16e3cae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import subprocess\n",
    "import json\n",
    "import pandas as pd\n",
    "import csv\n",
    "from ipyfilechooser import FileChooser\n",
    "import IPython.display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c93481",
   "metadata": {},
   "source": [
    "### 1. Lecture de vidéo\n",
    "\n",
    "Pour lire les vidéos et manipuler les images, nous allons utiliser la bibliothèque <a href='https://opencv.org/'>OpenCV<a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "0cd7eab4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46573cb6545d45b59e80a0f8960095c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileChooser(path='C:\\Users\\ReViVD\\Documents\\GitHub\\tuto-video-tracking', filename='test.txt', title='<b>FileCh…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "#Selection de l'image\n",
    "\n",
    "from ipyfilechooser import FileChooser\n",
    "import os\n",
    "\n",
    "# Create new FileChooser:\n",
    "# Path: current directory\n",
    "# File: test.txt\n",
    "# Title: <b>FileChooser example</b>\n",
    "# Show hidden files: no\n",
    "# Use the default path and filename as selection: yes\n",
    "# Only show folders: no\n",
    "fdialog_vid = FileChooser(\n",
    "    os.getcwd(),\n",
    "    filename='test.txt',\n",
    "    title='<b>FileChooser example</b>',\n",
    "    show_hidden=False,\n",
    "    select_default=True,\n",
    "    show_only_dirs=False\n",
    ")\n",
    "\n",
    "display(fdialog_vid)\n",
    "\n",
    "# Get the selected value\n",
    "fdialog_vid.selected\n",
    "\n",
    "# Callback example\n",
    "def change_title(chooser):\n",
    "    chooser.title = '<b>Sélection effectuée</b>'\n",
    "\n",
    "# Register callback function\n",
    "fdialog_vid.register_callback(change_title)\n",
    "\n",
    "# Set or change the title\n",
    "fdialog_vid.title = '<b>Selectionner une vidéo</b>'\n",
    "\n",
    "# Show hidden files, change rows to 10, and hide folder icons\n",
    "fdialog_vid.show_hidden = True\n",
    "fdialog_vid.rows = 10\n",
    "fdialog_vid.dir_icon = None\n",
    "\n",
    "# Change folder icon to `os.sep` and append it to the folder name\n",
    "fdialog_vid.dir_icon = os.sep\n",
    "fdialog_vid.dir_icon_append = True\n",
    "\n",
    "\n",
    "\n",
    "# Switch to folder-only mode\n",
    "fdialog_vid.show_only_dirs = True\n",
    "\n",
    "# Switch back to standard mode\n",
    "fdialog_vid.show_only_dirs = False\n",
    "\n",
    "\n",
    "# Set multiple file filter patterns (uses https://docs.python.org/3/library/fnmatch.html)\n",
    "fdialog_vid.filter_pattern = ['*.mp4', '*.avi']\n",
    "\n",
    "# Change the default path and filename\n",
    "fdialog_vid.default_path = os.path.abspath(os.getcwd())\n",
    "fdialog_vid.default_filename = 'readme.md'\n",
    "\n",
    "# Reset to defaults and clear the selected value\n",
    "fdialog_vid.reset()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "edb90288",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lecture de la vidéo\n",
    "video_name = fdialog_vid.selected\n",
    "\n",
    "vidcap = cv.VideoCapture(video_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09db2f33",
   "metadata": {},
   "source": [
    "### 2. Manipulation de frames\n",
    "\n",
    "Pour la manipulation de frames, nous allons reprendre la bibliothèque <a href='https://opencv.org/'>OpenCV<a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "a2e74ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extraction des frames\n",
    "if not os.path.isdir('output'):\n",
    "    os.mkdir('output')\n",
    "frame_path = os.path.join('output','frames')\n",
    "\n",
    "if not os.path.isdir(frame_path):\n",
    "    os.mkdir(frame_path)\n",
    "    \n",
    "success, image = vidcap.read()\n",
    "i = 0\n",
    "while success != False:\n",
    "    #Lecture des frames\n",
    "    success, image = vidcap.read()\n",
    "    \n",
    "    #Sauvegarder les frames\n",
    "    if success:\n",
    "        cv2.imwrite(os.path.join(frame_path, str(i) + \".jpg\"), image)\n",
    "    else:\n",
    "        break\n",
    "    \n",
    "    i += 1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055e7662",
   "metadata": {},
   "source": [
    "### 3. Estimation de la pose\n",
    "\n",
    "Pour faire l'estimation de pose, nous allons utiliser <a href='https://github.com/CMU-Perceptual-Computing-Lab/openpose'>Openpose<a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "617dd461",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Répertorier les frames dans le dossier où elles ont été sauvegardées\n",
    "\n",
    "os.chdir(dossier_courant)\n",
    "liste_frame = os.listdir(frame_path)\n",
    "\n",
    "if not os.path.isdir(os.path.join('output','openpose_json')):\n",
    "    os.mkdir(os.path.join('output','openpose_json'))\n",
    "#Lancer Openpose sur les frames, Choisir où on enregistre les frames\n",
    "chemin_sauvegarde = os.path.join('output','openpose_json')\n",
    "\n",
    "path_openpose = \"C:\\\\Users\\\\ReViVD\\\\Downloads\\\\openpose-1.7.0-binaries-win64-gpu-python3.7-flir-3d_recommended\\\\openpose\"\n",
    "dossier_courant = os.getcwd()\n",
    "os.chdir(path_openpose)\n",
    "if not os.path.isdir(chemin_sauvegarde):\n",
    "    os.mkdir(chemin_sauvegarde)\n",
    "subprocess.call(\"bin\\\\OpenPoseDemo.exe --video \"+os.path.join(dossier_courant,video_name)+\" --write_json \"+os.path.join(dossier_courant,chemin_sauvegarde)+' --write_video '+os.path.join(dossier_courant,video_name.replace('.mp4','_openpose.avi'))+' --display 0')\n",
    "\n",
    "#subprocess.call(\"bin\\\\OpenPoseDemo.exe --image_dir \"+os.path.join(dossier_courant,'test')+\" --write_images \"+os.path.join(dossier_courant,'test2')+\" --write_json \"+os.path.join(dossier_courant,chemin_sauvegarde)+ ' --display 0')\n",
    "os.chdir(dossier_courant)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ce6d6c",
   "metadata": {},
   "source": [
    "### Keypoints Openpose"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d18f169",
   "metadata": {},
   "source": [
    "<img src=\"utils/openpose_keypoints.png\" width=400 height=400 />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3311adb",
   "metadata": {},
   "source": [
    "### 4. Utilisation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "8050889e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Répertorier les json dans le dossier où elles ont été sauvegardées\n",
    "liste_json_openpose = os.listdir(chemin_sauvegarde)\n",
    "\n",
    "#Ouvrir les json et les récupérer les données\n",
    "liste_toutes_valeurs = []\n",
    "for le_json in liste_json_openpose:\n",
    "        if '.json' in le_json: #test pour vérifier que c'est bien un fichier json\n",
    "            data = pd.read_json(os.path.join(chemin_sauvegarde,le_json), lines=True)\n",
    "            if len(data['people'])>0: #test pour vérifier qu'il y a bien au moins une personne détectée\n",
    "                for i in range(len(data['people'][0])):\n",
    "                    data_keypoints = data['people'][0][i]['pose_keypoints_2d']\n",
    "                    for j in range(0,len(data_keypoints),3): #partie permettant de récupérer les coordonnées x, y et la confiance à chaque fois\n",
    "                        liste_un_json = []\n",
    "                        liste_un_json.append(int(le_json.split('_')[-2]))\n",
    "                        liste_un_json.append(i)\n",
    "                        liste_un_json.append(j//3)\n",
    "                        liste_un_json.append(data_keypoints[j])\n",
    "                        liste_un_json.append(data_keypoints[j+1])\n",
    "                        liste_un_json.append(data_keypoints[j+2])\n",
    "                        liste_toutes_valeurs.append(liste_un_json)\n",
    "\n",
    "#Créer un fichier csv à l'aide des json créés par Openpose\n",
    "chemin_csv_openpose = os.path.join('output','csv','openpose.csv') #chemin où on va enregistrer le csv contenant les informations openpose\n",
    "if not os.path.isdir(os.path.split(chemin_csv_openpose)[0]):\n",
    "    os.mkdir(os.path.split(chemin_csv_openpose)[0])\n",
    "    \n",
    "\n",
    "with open(chemin_csv_openpose,'w',newline='') as fichiercsv:\n",
    "    writer=csv.writer(fichiercsv)\n",
    "    writer.writerow(['frame','numero_pers','joint','x','y','confience'])\n",
    "    for l in liste_toutes_valeurs:\n",
    "        writer.writerow(l)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "e7b215e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fonction permettant de tracer un rectangle à l'aide de 4 points\n",
    "def draw_rect_video(frame, posA = (10, 50), posB = (20, 70), color = (255,0,0)):\n",
    "    \"\"\"draw a rectangle given 2 points\"\"\"\n",
    "    #c = hex2rgb(colors[0])\n",
    "    #color = (c[2], c[1], c[0])\n",
    "    thickness = 6\n",
    "    cv2.rectangle(frame, posA, posB, color, thickness)\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "#Tracer des bounding box autour des joueurs à l'aide de l'estimation de pose\n",
    "def bounding_box(num_frame,chemin_image,num_personne,chemin_csv,chemin_sauvegarder,afficher_image=True):\n",
    "    if not os.path.isdir(chemin_sauvegarder):\n",
    "        os.mkdir(chemin_sauvegarder)\n",
    "    #Ouvir le fichier csv\n",
    "    with open(chemin_csv, newline='') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        next(reader) #permet de ne pas prendre l'en-tête\n",
    "        max_x,max_y,min_x,min_y = -1,-1,-1,-1\n",
    "        for row in reader:\n",
    "            if ((int(row[0]) == num_frame) and (int(row[1]) == num_personne)):\n",
    "                if max_x == -1:\n",
    "                    max_x,max_y,min_x,min_y = float(row[3]),float(row[4]),float(row[3]),float(row[4])\n",
    "                else:\n",
    "                    if ((float(row[3]) > max_x)):\n",
    "                        max_x = float(row[3])\n",
    "                    if ((float(row[4]) > max_y)):\n",
    "                        max_y = float(row[4])\n",
    "                    if (((float(row[3]) < min_x) or (min_x == 0)) and (float(row[3]) != 0)):\n",
    "                        min_x = float(row[3])\n",
    "                    if (((float(row[4]) < min_y) or (min_y == 0)) and (float(row[4]) != 0)):\n",
    "                        min_y = float(row[4])\n",
    "    \n",
    "    image = cv2.imread(chemin_image) #lire image\n",
    "    draw_rect_video(image, (int(max_x),int(max_y)), (int(min_x),int(min_y))) #tracer rectangle\n",
    "    \n",
    "    cv2.imwrite(os.path.join(chemin_sauvegarder,str(num_frame)+'.jpg'),image) #enregistrer image avec box\n",
    "    \n",
    "    if afficher_image:\n",
    "        IPython.display.display(Image(os.path.join(chemin_sauvegarder,str(num_frame)+'.jpg')))\n",
    "            \n",
    "#bounding_box(0,os.path.join('output','0.jpg'),0,'openpose.csv',os.path.join('output','frames_boxes'))\n",
    "#Faire des premiers calculs de métrics (vitesses, distances de déplacements,...)\n",
    "#Faire bounding box Couleur de la raquette\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "9834c497",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tracer les box d'une personne sur tout un dossier\n",
    "nom_dossier = os.path.join('output','frames')\n",
    "liste_images = os.listdir(nom_dossier)\n",
    "liste_images.sort()\n",
    "liste_images.sort(key=len)\n",
    "num_personne = 0\n",
    "for i in range(len(liste_images)):\n",
    "    bounding_box(i,os.path.join(nom_dossier,liste_images[i]),num_personne,os.path.join('output','csv','openpose.csv'),os.path.join('output','frames_boxes'),afficher_image=False)\n",
    "    bounding_box(i,os.path.join(nom_dossier.replace('frames','frames_boxes'),liste_images[i]),1,os.path.join('output','csv','openpose.csv'),os.path.join('output','frames_boxes'),afficher_image=False)    \n",
    "    bounding_box(i,os.path.join(nom_dossier.replace('frames','frames_boxes'),liste_images[i]),2,os.path.join('output','csv','openpose.csv'),os.path.join('output','frames_boxes'),afficher_image=False)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
