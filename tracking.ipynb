{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be302b0e",
   "metadata": {},
   "source": [
    "# Notebook sur le tracking vidéo\n",
    "\n",
    "Dans ce notebook nous allons voir comment on peut lire une vidéo, extraire les frames de la vidéo, faire de la détection (estimation de pose) et faire du tracking sur cette détection.\n",
    "\n",
    "**Plan:**\n",
    "1. Lecture de vidéo\n",
    "2. Manipulation de frames\n",
    "3. Estimation de pose\n",
    "4. Utilisation des données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcde2ab",
   "metadata": {},
   "source": [
    "### 0. Import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f59774c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8250a74",
   "metadata": {},
   "source": [
    "### 1. Lecture de vidéo\n",
    "\n",
    "Pour lire les vidéos et manipuler les images, nous allons utiliser la bibliothèque <a href='https://opencv.org/'>OpenCV<a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a061ce04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lecture de la vidéo\n",
    "video_name = 'A DEFINIR' #le chemin de la vidéo\n",
    "\n",
    "vidcap = cv.VideoCapture(video_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61bc85f",
   "metadata": {},
   "source": [
    "### 2. Manipulation de frames\n",
    "\n",
    "Pour la manipulation de frames, nous allons reprendre la bibliothèque <a href='https://opencv.org/'>OpenCV<a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09505f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extraction des frames\n",
    "frame_path = 'A DEFINIR' #le chemin du dossier où on va enregistrer les frames\n",
    "\n",
    "if not os.path.isfile(frame_path):\n",
    "    os.path.mkdir(frame_path)\n",
    "    \n",
    "success, image = vidcap.read()\n",
    "i = 0\n",
    "while success != False:\n",
    "    i = i + 1\n",
    "    #Lecture des frames\n",
    "    success, image = vidcap.read()\n",
    "    \n",
    "    #Sauvegarder les frames\n",
    "    if i == n and success:\n",
    "        cv2.imwrite(os.path.join(frame_path, str(n) + \"th_frame\" + \".jpg\"), image)\n",
    "    else:\n",
    "        break\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6d0684",
   "metadata": {},
   "source": [
    "### 3. Estimation de la pose\n",
    "\n",
    "Pour faire l'estimation de pose, nous allons utiliser <a href='https://github.com/CMU-Perceptual-Computing-Lab/openpose'>Openpose<a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2013b23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Répertorier les frames dans le dossier où elles ont été sauvegardées\n",
    "liste_frame = os.listdir(frame_path)\n",
    "\n",
    "#Lancer Openpose sur les frames, Choisir où on enregistre les frames\n",
    "chemin_sauvegarde = 'A DEFINIR' #le dossier où sauvegarder les json openpose\n",
    "for frame in liste_frame:\n",
    "    nom_json = 'A DEFINIR' #le nom du json openpose\n",
    "    fonction_openpose(frame,os.path.join(chemin_sauvegarde,nom_json))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40516643",
   "metadata": {},
   "source": [
    "### 4. Utilisation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae2f075",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Répertorier les json dans le dossier où elles ont été sauvegardées\n",
    "liste_json_openpose = os.listdir(chemin_sauvegarde)\n",
    "\n",
    "#Ouvrir les json et les récupérer les données\n",
    "liste_toutes_valeurs = []\n",
    "for json in liste_json_openpose:\n",
    "        if '.json' in les_json: #test pour vérifier que c'est bien un fichier json\n",
    "            with open(os.path.join(chemin_sauvegarde,json)) as mon_json:\n",
    "                data = json.load(mon_json)\n",
    "                if len(data['people'])>0: #test pour vérifier qu'il y a bien au moins une personne détectée\n",
    "                    for i in range(len(data['people'])):\n",
    "                        data_keypoints = data['people'][i]['pose_keypoints_2d']\n",
    "                        for j in range(0,len(data_keypoints),3): #partie permettant de récupérer les coordonnées x, y et la confiance à chaque fois\n",
    "                            liste_un_json = []\n",
    "                            liste_un_json.append(int(les_json.split('_')[-2]))\n",
    "                            liste_un_json.append(i)\n",
    "                            liste_un_json.append(j//3)\n",
    "                            liste_un_json.append(data_keypoints[j])\n",
    "                            liste_un_json.append(data_keypoints[j+1])\n",
    "                            liste_un_json.append(data_keypoints[j+2])\n",
    "                            liste_toutes_valeurs.append(liste_un_json)\n",
    "\n",
    "#Créer un fichier csv à l'aide des json créés par Openpose\n",
    "chemin_csv_openpose = 'A DEFINIR' #chemin où on va enregistrer le csv contenant les informations openpose\n",
    "with open(chemin_csv_openpose,'w',newline='') as fichiercsv:\n",
    "    writer=csv.writer(fichiercsv)\n",
    "    writer.writerow(['frame','numero_pers','joint','x','y','confience'])\n",
    "    for l in liste_toutes_valeurs:\n",
    "        writer.writerow(l)\n",
    "\n",
    "#Ouvir le fichier csv\n",
    "\n",
    "#Réidentifier d'une frame à l'autre les personnes présentes sur la vidéo (tracking)\n",
    "\n",
    "#Faire des premiers calculs de métrics (vitesses, distances de déplacements,...)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
