{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c27ee2c",
   "metadata": {},
   "source": [
    "# Notebook sur le tracking vidéo\n",
    "\n",
    "Dans ce notebook nous allons voir comment on peut lire une vidéo, extraire les frames de la vidéo, faire de la détection (estimation de pose) et faire du tracking sur cette détection.\n",
    "\n",
    "**Plan:**\n",
    "1. Lecture de vidéo\n",
    "2. Manipulation de frames\n",
    "3. Estimation de pose\n",
    "4. Utilisation des données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193d40b1",
   "metadata": {},
   "source": [
    "### 0. Import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8499c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8501cb",
   "metadata": {},
   "source": [
    "### 1. Lecture de vidéo\n",
    "\n",
    "Pour lire les vidéos et manipuler les images, nous allons utiliser la bibliothèque <a href='https://opencv.org/'>OpenCV<a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b033ea59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lecture de la vidéo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a044857",
   "metadata": {},
   "source": [
    "### 2. Manipulation de frames\n",
    "\n",
    "Pour la manipulation de frames, nous allons reprendre la bibliothèque <a href='https://opencv.org/'>OpenCV<a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10291d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extraction des frames\n",
    "\n",
    "#Sauvegarder les frames\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1018ed8d",
   "metadata": {},
   "source": [
    "### 3. Estimation de la pose\n",
    "\n",
    "Pour faire l'estimation de pose, nous allons utiliser <a href='https://github.com/CMU-Perceptual-Computing-Lab/openpose'>Openpose<a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b5e65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Répertorier les frames dans le dossier où elles ont été sauvegardées\n",
    "\n",
    "#Lancer Openpose sur les frames, Choisir où on enregistre les frames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb638753",
   "metadata": {},
   "source": [
    "### 4. Utilisation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ceb8ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Répertorier les json dans le dossier où elles ont été sauvegardées\n",
    "\n",
    "#Ouvrir les json et les récupérer les données\n",
    "\n",
    "#Créer un fichier csv à l'aide des json créés par Openpose\n",
    "\n",
    "#Ouvir le fichier csv\n",
    "\n",
    "#Réidentifier d'une frame à l'autre les personnes présentes sur la vidéo (tracking)\n",
    "\n",
    "#Faire des premiers calculs de métrics (vitesses, distances de déplacements,...)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
